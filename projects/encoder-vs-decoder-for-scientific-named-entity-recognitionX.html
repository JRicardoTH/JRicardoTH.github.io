<!DOCTYPE html>
<html lang="en">

<!-- <head>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@400;500;600;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <title> Title </title>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/main.css" />
    <link rel="shortcut icon" type="image/x-icon" href="images/teal 4.png">
</head> -->

<head>
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@400;500;600;700&display=swap"
        rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Highlight.js style (pick any theme) -->
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">

  <!-- Highlight.js library -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

  <!-- Initialize Highlight.js -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      hljs.highlightAll();
    });
  </script>

    <!-- Highlight.js Line Numbers plugin -->
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>

  <!-- Initialize line numbers -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      hljs.highlightAll();
      hljs.initLineNumbersOnLoad();
    });
  </script>


  <script>

  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        tags: 'ams',              // <-- enables equation numbering + references
      },
      svg: { fontCache: 'global' }
    };
  </script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<!-- 
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script> -->
  <title> SciNER with Encoders vs Decoders — Project</title>
  <link rel="stylesheet" href="../css/main.css?v=1" />
</head>

<body>
    <div class="top-menu-left">
        <a class="menu-link-left" href="../index.html"><i class="fa-solid fa-arrow-left"></i> Back to Projects</a>
        <!-- <a class="menu-link" href="../index.html">Projects</a>
        <a class="menu-link" href="../cv.html">CV</a>
        <a class="menu-link" href="../about.html">About Me</a> -->
    </div>

  <main class="project-details">
    <h1> Evaluating Encoder vs Decoder Models for Scientific Named Entity Recognition </h1>
    <h2 class="article-subtitle"> José Ricardo Torres Heredia </h2>
    <br>

    <img src="../images/NER.png" alt="Project img" class="article__img">
    <br>
    <p>
      Named Entity Recognition (NER) is a natural language processing task to find and classify semantic forms in text belonging to 
      predefined categories (e.g. person, organization, location), turning unstructured text into structured data. This is often done
      alongside relation extraction between elements in those categories. NER is useful for information retrieval,
      text summarization, question answering, machine translation, knowledge base construction, etc. 
      In this article, we explore the scientific literature for Scientific Named Entity Recognition (SciNER) using and comparing
      pre-trained encoders to zero and few-shot decoders. This is achieved using SciERC (Scientific Entity Recognition and Classification)
      <a href="https://arxiv.org/abs/1808.09602" class="ref-link"></a>, a sentence-level NER + relation extraction dataset built from 
      AI / ML research papers. It is a JSONL file structured in the following way. The single data point or line in the dataset 
      corresponding to the abstract 
    </p>
    <blockquote class="quote">
      In this paper we describe and evaluate a Question Answering system that goes beyond answering factoid questions. We focus on 
      FAQ-like questions and answers, and build our system around a noisy-channel architecture which exploits both a language model 
      for answers and a transformation model for answer/question terms, trained on a corpus of 1 million question/answer pairs 
      collected from the Web.
    </blockquote>    
    <p>
      would look like this
    </p>
    <blockquote class="pseudoalgorithm">
      {
      "clusters": [[[8, 10], [29, 29]]],<br>
      "sentences": [["In", "this", "paper", "we", "describe", "and", "evaluate", "a", "Question", "Answering", "system", "that", <span class="hspace"></span>
          "goes", "beyond", "answering", "factoid", "questions", "."], ["We", "focus", "on", "FAQ-like", "questions", "and", <span class="hspace"></span>
          "answers", ",", "and", "build", "our", "system", "around", "a", "noisy-channel", "architecture", "which", "exploits", <span class="hspace"></span>
          "both", "a", "language", "model", "for", "answers", "and", "a", "transformation", "model", "for", "answer/question", <span class="hspace"></span>
          "terms", ",", "trained", "on", "a", "corpus", "of", "1", "million", "question/answer", "pairs", "collected", "from", <span class="hspace"></span>
          <span class="hspace"></span>
          "the", "Web", "."]], <br>
      "ner": [[[8, 10, "Method"]], [[21, 24, "Material"], [29, 29, "Generic"], [32, 33, "Method"], [38, 39, "Method"], <span class="hspace"></span>
          <span class="hspace"></span>
          [44, 45, "Method"], [62, 62, "Material"]]],<br>
      "relations": [[], [[29, 29, 21, 24, "USED-FOR"], [32, 33, 29, 29, "USED-FOR"], [32, 33, 38, 39, "USED-FOR"], <span class="hspace"></span>
          <span class="hspace"></span>
          [32, 33, 44, 45, "USED-FOR"]]], <br>
      "doc_key": "N04-1008"
      }
    </blockquote>    
    <p>
      where the clusters token start and end spans indicate parts of the text referring to the same concept per list (e.g. "system" on 
      token 29 refers to "Question Answering system" on tokens 8-10); the NER spans outline the entity and categorize it as either "Task",
      "Method", "Metric", "Material", "OtherScientificTerm" or "Generic"; and the relations dictionary entries indicate spans for the first
      and second entities and their relation as one of the following: "COMPARE", "PART-OF", "CONJUNCTION", "EVALUATE-FOR", "FEATURE-OF", 
      "USED-FOR" and "HYPONYM-OF".
    </p>



    </p>

    <h3> Preprocessing </h3>
    
    <p>
      We first load each JSONL file as a pandas DataFrame:
    </p>
    <pre><code class="language-python">
      base_path = '/content/sciner-methods/data'
      file_map = {"TRAIN_SET" : "train",
                  "TEST_SET" : "test",
                  "VALIDATION_SET" : "dev"}
      datasets = {}

      for name, filename in file_map.items():
        file_path = f"{base_path}/{filename}.json"

        try:
            df = pd.read_json(file_path, lines=True)
            print(f"\n DataFrame Columns and Data Types for {name}:")
            df.info()
            datasets[name] = df

        except FileNotFoundError:
            print(f"Error: The file '{file_path}' was not found. Please ensure the path is correct.")
        except Exception as e:
            print(f"An unexpected error occurred: {e}")
    </code></pre>
    <p>
      We then flatten sentence tokens of each abstract into one list of tokens per abstract and then join them into a string with correct
      punctiation.
    </p>
    <pre><code class="language-python">
      def flatten_and_detokenize(record):
      # Flatten sentence tokens into one list per data point (abstract)
      tokens = [tok for sent in record["sentences"] for tok in sent]

      # Join flattened sentence tokens and fix all leftover spaces between punctuation symbols.
      text = " ".join(tokens)
      text = re.sub(r"\s+([.,!?;:%\)\]])", r"\1", text)
      text = re.sub(r"\(\s+", "(", text)
      text = re.sub(r"\s+'s\b", "'s", text)
      text = re.sub(r"\s+'s\b", "'s", text)
      return text
    </code></pre>
    <p>
      
    </p>



    <pre><code class="language-python">

    </code></pre>
    <p>
      
    </p>
    <pre><code class="language-python">

    </code></pre>
    <p>
      
    </p>
    <pre><code class="language-python">

    </code></pre>
    <p>
      
    </p>
    <pre><code class="language-python">

    </code></pre>




    <ul>
      <li>Data preprocessing in Python notebooks</li>
      <li>Model comparison using Azure AutoML</li>
      <li>Deploying the best model as an API endpoint</li>
      <li>Testing the deployed inference endpoint</li>
    </ul>

    <!-- <a href="../index.html" class="back-link">← Back to Projects</a> -->
  </main>

</body>
</html>
